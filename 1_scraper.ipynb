{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qk38OrdhUGvj"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import platform\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Start Chromedriver\n",
    "- **`CHROME_VERSION`**: go to your chrome settings and check your version of chrome. If your version does not match the version shown below, download the correct version of the Chromedriver from [here](https://chromedriver.chromium.org/downloads) and append the version number to the end of its name. e.g. if you have Chrome version 80, you should rename `chromedriver.exe` to `chromedriver80.exe`\n",
    "  - **`Options()`**: adding `headless` and `window-size` arguments allows us to use Chromedriver without a GUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHROME_VERSION='79'  # change this to match Chrome version on host machine\n",
    "\n",
    "options = Options()\n",
    "options.add_argument('headless')\n",
    "options.add_argument('window-size=1200x600')\n",
    "\n",
    "global driver\n",
    "if platform.system() == 'Windows':\n",
    "    driver = webdriver.Chrome(f'./chromedriver/chromedriver{CHROME_VERSION}.exe', options=options)\n",
    "else:\n",
    "    driver = webdriver.Chrome(f'./chromedriver/chromedriver{CHROME_VERSION}', options=options)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Load upcoming Super Rugby match odds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YpZqaHD8WR-5"
   },
   "outputs": [],
   "source": [
    "driver.get( \"https://www.oddsportal.com/rugby-union/world/super-rugby/\")\n",
    "driver.implicitly_wait(5)  # give page time to load all content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a peek at what the Chromedriver sees using the `get_screenshot_as_png()` method on the driver object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        driver.get_screenshot_as_png(),\n",
    "        width=800,\n",
    "        height=400\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = driver.find_element_by_xpath('//*[@id=\"tournamentTable\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.find_elements_by_xpath('//*[@id=\"tournamentTable\"]/tbody/tr[7]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_rows = table.text.split('\\n')\n",
    "table_rows[:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove table header (first 5 lines)\n",
    "table_rows = table_rows[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split list up by dates\n",
    "date_idx = []\n",
    "idx = 0\n",
    "for row in table_rows:\n",
    "    if \"1 X 2 B's\" in row:\n",
    "        print(row)\n",
    "        date_idx.append(idx)\n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema of dataframe\n",
    "df = {\n",
    "    'Date': [],\n",
    "    'Home Team': [],\n",
    "    'Away Team': [],\n",
    "    'Home Score': [],\n",
    "    'Away Score': [],\n",
    "    'Play-off Game?': [],\n",
    "    'Home Odds': [],\n",
    "    'Draw Odds': [],\n",
    "    'Away Odds': [],\n",
    "    'Bookmakers Surveyed': []\n",
    "}\n",
    "\n",
    "# for each separate date\n",
    "for i in range(len(date_idx)):\n",
    "    \n",
    "    # extract date\n",
    "    date = table_rows[date_idx[i]]\n",
    "    date = date.replace(\" 1 X 2 B's\", '')\n",
    "    \n",
    "    # remove unnecessary text\n",
    "    if 'Tomorrow' in date or 'Today' in date:\n",
    "        date = date[date.find(',')+2: ] + ' ' + str(datetime.datetime.now().year)\n",
    "        \n",
    "    date = date.replace(' ', '-')\n",
    "    \n",
    "    first_match = date_idx[i]+1\n",
    "    \n",
    "    fixtures = []\n",
    "    \n",
    "    if i < len(date_idx)-1:\n",
    "        last_match = date_idx[i+1]\n",
    "        fixtures = table_rows[first_match:last_match]\n",
    "        \n",
    "    else:\n",
    "        fixtures = table_rows[first_match:]\n",
    "        \n",
    "    fixtures = np.array(fixtures).reshape(-1, 5)\n",
    "    date_col = np.repeat([date], fixtures.shape[0])\n",
    "    fixtures = np.hstack((date_col.reshape(-1, 1), fixtures))\n",
    "    \n",
    "    # add each row to dictionary\n",
    "    for f in fixtures:\n",
    "        df['Date'].append(f[0])\n",
    "        df['Home Team'].append(f[1])\n",
    "        df['Away Team'].append(f[1])\n",
    "        df['Home Score'].append(0)\n",
    "        df['Away Score'].append(0)\n",
    "        df['Play-off Game?'].append('')\n",
    "        df['Home Odds'].append(f[2])\n",
    "        df['Draw Odds'].append(f[3])\n",
    "        df['Away Odds'].append(f[4])\n",
    "        df['Bookmakers Surveyed'].append(f[-1])\n",
    "\n",
    "# convert dictionary to dataframe\n",
    "df = pd.DataFrame(df)\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_home(s):\n",
    "    '''find the text between the kick-off time and the dash'''\n",
    "    return re.search(r'[0-2][0-9]:[0-6][0-9](.*?)-', s).group(1).strip()\n",
    "\n",
    "def get_away(s):\n",
    "    '''find the last word of text'''\n",
    "    return s.split()[-1]\n",
    "\n",
    "print(get_home('06:05 Blues - Chiefs'))\n",
    "print(get_away('06:05 Blues - Chiefs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Home Team'] = df['Home Team'].apply(get_home)\n",
    "df['Away Team'] = df['Away Team'].apply(get_away)\n",
    "\n",
    "df.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch Existing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in existing data\n",
    "existing_dataset = pd.read_csv('./data/super_rugby_oddsportal.csv')\n",
    "\n",
    "# replace NaNs with empty strings\n",
    "existing_dataset.fillna('', inplace=True)\n",
    "\n",
    "existing_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Scraped Odds to Existing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new odds to existing\n",
    "combined_df = pd.concat([df, existing_dataset], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Updated Dataset to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv('./data/super_rugby_oddsportal.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Oddsportal Web Scraper",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
